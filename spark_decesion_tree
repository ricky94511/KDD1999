package bigdata

/**
 * Created by Alision on 2014/12/11.
 */
import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf
import java.sql.Timestamp
import org.apache.spark.mllib.tree.DecisionTree
import org.apache.spark.mllib.util.MLUtils


object decesion_tree {
  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("decesion_tree")
    val sc = new SparkContext(conf)
    val data = MLUtils.loadLibSVMFile(sc, "s3n://chocolabs-emr/output/sparkoutput/tvuser_trainingdata_libsvm/kdd1999",true,41).cache()
    val splits = data.randomSplit(Array(0.8, 0.2))
    val (trainingData, testData) = (splits(0), splits(1))
    // Train a DecisionTree model.
    //  Empty categoricalFeaturesInfo indicates all features are continuous.
    val numClasses = 24
    val categoricalFeaturesInfo = Map[Int, Int](1->2)
    val impurity = "gini"
    val maxDepth = 5
    val maxBins = 100

    val model = DecisionTree.trainClassifier(trainingData, numClasses, categoricalFeaturesInfo, impurity,
      maxDepth, maxBins)

    // Evaluate model on training instances and compute training error
    val labelAndPreds = data.map { point =>
      val prediction = model.predict(point.features)
      (point.label, prediction)
    }
    labelAndPreds.saveAsTextFile("s3n://chocolabs-emr/output/sparkoutput/decesion_tree")
    val trainErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / data.count
    println("Training Error = " + trainErr)
    println("Learned classification tree model:\n" + model)
  }
}
